{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a428eda-752a-4354-a1dd-b3aebd55ec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\wowdao\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy\n",
    "import implicit \n",
    "import mlflow\n",
    "from prefect import flow, task\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "import pickle \n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a9a0fa-ab8c-4dca-afc5-f6a6686d8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = pd.read_csv(\"./train_triplets.txt/train_triplets.txt\", delimiter = \"\\t\", names = [\"user_id\", \"song_id\", \"play_count\"], engine = \"pyarrow\", dtype_backend = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d03cc74b-d3c2-4fb8-90c0-d2c79562ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_info = pd.read_csv(\"./song_data.csv\", engine = \"pyarrow\", dtype_backend=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3eeeefe-c86f-4a5f-9bd3-70009312b621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ArrowExtensionArray>\n",
       "['SOAKIMP12A8C130995', 'SOAPDEY12A81C210A9', 'SOBBMDR12A8C13253B',\n",
       " 'SOBFNSP12AF72A0E22', 'SOBFOVM12A58A7D494', 'SOBNZDC12A6D4FC103',\n",
       " 'SOBSUJE12A6D4F8CF5', 'SOBVFZR12A6D4F8AE3', 'SOBXALG12A8C13C108',\n",
       " 'SOBXHDL12A81C204C0',\n",
       " ...\n",
       " 'SOOFPQN12AB01884A6', 'SOSJRJM12A6701D41E', 'SOXWNXJ12A6701D974',\n",
       " 'SOPGGXJ12AB018622A', 'SOFYWFV12A6D4F4A7E', 'SOJLGCD12A6D4F4A7C',\n",
       " 'SONYEUK12A8C13E9A4', 'SOUSSCZ12A8C131D83', 'SOKSHWF12AB018B8CC',\n",
       " 'SOCDLVW12AB018371F']\n",
       "Length: 384546, dtype: string[pyarrow]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.song_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c19f81d-fb69-49f4-a1e9-b5425222112c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'song_id', 'play_count'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5c31cb4-fcf1-436f-a715-07bd517eab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['song_id', 'title', 'release', 'artist_name', 'year'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5ff979c-9864-4f41-b6f1-b7e1c7228c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user_item = user_item.iloc[:10**6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8912e1d-a303-4903-a3f5-7c8e0407e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "taste_profile = sample_user_item.merge(song_info, on = \"song_id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8418d091-a060-42fe-979d-92adbce332e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "      <td>The Cove</td>\n",
       "      <td>Thicker Than Water</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAPDEY12A81C210A9</td>\n",
       "      <td>1</td>\n",
       "      <td>Nothing from Nothing</td>\n",
       "      <td>To Die For</td>\n",
       "      <td>Billy Preston</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "      <td>Entre Dos Aguas</td>\n",
       "      <td>Flamenco Para Niños</td>\n",
       "      <td>Paco De Lucia</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFNSP12AF72A0E22</td>\n",
       "      <td>1</td>\n",
       "      <td>Under Cold Blue Stars</td>\n",
       "      <td>Under Cold Blue Stars</td>\n",
       "      <td>Josh Rouse</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFOVM12A58A7D494</td>\n",
       "      <td>1</td>\n",
       "      <td>Riot Radio (Soundtrack Version)</td>\n",
       "      <td>Nick &amp; Norah's Infinite Playlist - Original Mo...</td>\n",
       "      <td>The Dead 60s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id             song_id  play_count  \\\n",
       "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1   \n",
       "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9           1   \n",
       "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2   \n",
       "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22           1   \n",
       "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494           1   \n",
       "\n",
       "                             title  \\\n",
       "0                         The Cove   \n",
       "1             Nothing from Nothing   \n",
       "2                  Entre Dos Aguas   \n",
       "3            Under Cold Blue Stars   \n",
       "4  Riot Radio (Soundtrack Version)   \n",
       "\n",
       "                                             release    artist_name  year  \n",
       "0                                 Thicker Than Water   Jack Johnson     0  \n",
       "1                                         To Die For  Billy Preston  1974  \n",
       "2                                Flamenco Para Niños  Paco De Lucia  1976  \n",
       "3                              Under Cold Blue Stars     Josh Rouse  2002  \n",
       "4  Nick & Norah's Infinite Playlist - Original Mo...   The Dead 60s     0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taste_profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1482abe1-5c7b-4253-a22b-8df260921e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "taste_profile[\"song\"] = taste_profile[\"artist_name\"] + \" - \" + taste_profile[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b857745-3d61-4bfa-b49e-13faedf4e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "taste_profile = taste_profile.drop(columns = [\"title\", \"artist_name\", \"release\", \"year\"]).reindex(columns = [\"user_id\", \"song_id\", \"song\", \"play_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4dde3eae-9f4d-4695-9df6-591c1639bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "taste_profile[\"numeric_user_id\"], _ = pd.factorize(taste_profile[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac8dbc67-54b9-484c-b20a-8b1994ce594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taste_profile[\"numeric_song_id\"], _ = pd.factorize(taste_profile[\"song_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ec328478-7f6f-472c-bce6-bf6a84349f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "taste_profile = taste_profile.drop(index = taste_profile[taste_profile.play_count >= 15].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d3cbd-ee3a-4617-a637-36aa08af0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_profile = pd.DataFrame(columns = [\"user_id\", \"song_id\", \"song\", \"play_count\", \"numeric_user_id\", \"numeric_song_id\"])\n",
    "test_profile = pd.DataFrame(columns = [\"user_id\", \"song_id\", \"song\", \"play_count\", \"numeric_user_id\", \"numeric_song_id\"])\n",
    "\n",
    "for user in taste_profile[\"user_id\"].unique():\n",
    "    data = taste_profile[taste_profile[\"user_id\"] == user]\n",
    "    user_train, user_test = train_test_split(data, test_size = 0.2, random_state = 42)\n",
    "    train_profile = pd.concat([train_profile, user_train])\n",
    "    test_profile = pd.concat([test_profile, user_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "176b3f01-3dfa-4904-aa96-b7ddb41b1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_profile_train = train_profile.drop(columns = [\"user_id\", \"song_id\"]).reindex(columns = [\"numeric_user_id\", \"numeric_song_id\", \"play_count\", \"song\"])\n",
    "sample_profile_test = test_profile.drop(columns = [\"user_id\", \"song_id\"]).reindex(columns = [\"numeric_user_id\", \"numeric_song_id\", \"play_count\", \"song\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "00e4d393-bc23-4ede-94e8-0c15d46a6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_profile = sample_profile.set_index([\"numeric_user_id\", \"numeric_song_id\"])\n",
    "sample_profile_train = sample_profile_train.set_index([\"numeric_user_id\", \"numeric_song_id\"])\n",
    "sample_profile_test = sample_profile_test.set_index([\"numeric_user_id\", \"numeric_song_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "aa436482-f43b-441d-ab00-7f4b5c33efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_matrix(sample_profile):     \n",
    "    coo = scipy.sparse.coo_matrix(\n",
    "        (\n",
    "            sample_profile.play_count.astype(float), \n",
    "            (\n",
    "                sample_profile.index.get_level_values(0), \n",
    "                sample_profile.index.get_level_values(1),\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    csr_matrix = coo.tocsr()\n",
    "    return csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a796c61b-50af-45ea-8d7c-3dc9ac31f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = get_sparse_matrix(sample_profile_train)\n",
    "test_matrix = get_sparse_matrix(sample_profile_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "aafce9f5-cfa4-4e28-9841-c6963c7519be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20787x148039 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 973731 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8a1cced2-aae6-4cf2-8ed5-6bfa5316940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model = implicit.als.AlternatingLeastSquares(factors = 50, iterations = 10, regularization = 0.01)\n",
    "lmf_model = implicit.lmf.LogisticMatrixFactorization(factors = 50, iterations = 10, regularization = 0.01)\n",
    "\n",
    "als_model.fit(csr_matrix)\n",
    "lmf_model.fit(csr_matrix)\n",
    "\n",
    "recommendations, scores = implicit_model.recommend(10, csr_matrix[20], N = 20)\n",
    "rec, scr = lmf_model.recommend(10, csr_matrix[1000], N = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "7f121822-b11a-496f-b25f-551159d6ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  7%|6         | 1/15 [00:13<03:09, 13.56s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 2/15 [00:25<02:44, 12.65s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 3/15 [00:38<02:32, 12.67s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 4/15 [00:50<02:18, 12.57s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 5/15 [01:02<02:03, 12.35s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 6/15 [01:14<01:50, 12.29s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 7/15 [01:27<01:39, 12.38s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 8/15 [01:41<01:30, 12.86s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 9/15 [01:58<01:25, 14.32s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 10/15 [02:14<01:13, 14.66s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 11/15 [02:32<01:03, 15.75s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 12/15 [02:54<00:53, 17.71s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 13/15 [03:20<00:40, 20.10s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 14/15 [03:53<00:24, 24.09s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [04:28<00:00, 27.48s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [04:28<00:00, 17.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [17:23<1:09:35, 1043.91s/trial, best loss: -0.2855770985859546]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  7%|6         | 1/15 [00:17<04:05, 17.55s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 2/15 [00:31<03:24, 15.71s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 3/15 [00:45<02:58, 14.84s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 4/15 [00:58<02:35, 14.17s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 5/15 [01:12<02:19, 14.00s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 6/15 [01:28<02:10, 14.49s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 7/15 [01:43<01:59, 14.93s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 8/15 [02:00<01:47, 15.40s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 9/15 [02:19<01:38, 16.48s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 10/15 [02:38<01:26, 17.30s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 11/15 [02:58<01:12, 18.15s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 12/15 [03:19<00:56, 18.92s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 13/15 [03:41<00:40, 20.11s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 14/15 [04:04<00:20, 20.76s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [04:31<00:00, 22.60s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [04:31<00:00, 18.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [30:16<44:13, 884.38s/trial, best loss: -0.2855770985859546]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  7%|6         | 1/15 [00:09<02:12,  9.47s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 2/15 [00:18<02:00,  9.30s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 3/15 [00:28<01:55,  9.66s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 4/15 [00:37<01:43,  9.39s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 5/15 [00:46<01:32,  9.25s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 6/15 [00:55<01:21,  9.07s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 7/15 [01:03<01:11,  8.90s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 8/15 [01:13<01:03,  9.06s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 9/15 [01:23<00:56,  9.40s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 10/15 [01:34<00:49,  9.90s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 11/15 [01:44<00:39,  9.95s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 12/15 [01:55<00:30, 10.11s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 13/15 [02:05<00:20, 10.14s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 14/15 [02:15<00:10, 10.25s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [02:27<00:00, 10.57s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [02:27<00:00,  9.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [38:27<23:29, 704.63s/trial, best loss: -0.2855770985859546]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  7%|6         | 1/15 [00:06<01:34,  6.75s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 2/15 [00:12<01:23,  6.41s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 3/15 [00:18<01:14,  6.19s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 4/15 [00:24<01:07,  6.15s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 5/15 [00:31<01:03,  6.39s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 6/15 [00:37<00:56,  6.23s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 7/15 [00:43<00:49,  6.16s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 8/15 [00:49<00:42,  6.07s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 9/15 [00:55<00:35,  5.96s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 10/15 [01:01<00:29,  5.89s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 11/15 [01:07<00:23,  5.98s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 12/15 [01:13<00:18,  6.05s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 13/15 [01:19<00:12,  6.19s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 14/15 [01:26<00:06,  6.29s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [01:36<00:00,  7.45s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [01:36<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [45:59<10:04, 604.98s/trial, best loss: -0.2855770985859546]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  7%|6         | 1/15 [00:08<01:54,  8.20s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 2/15 [00:16<01:46,  8.21s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 3/15 [00:24<01:35,  7.97s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 4/15 [00:31<01:26,  7.84s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 5/15 [00:39<01:17,  7.73s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 6/15 [00:47<01:09,  7.77s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 7/15 [00:54<01:02,  7.78s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 8/15 [01:03<00:56,  8.07s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 9/15 [01:12<00:49,  8.26s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 10/15 [01:20<00:41,  8.32s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 11/15 [01:29<00:33,  8.45s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 12/15 [01:37<00:25,  8.45s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 13/15 [01:46<00:17,  8.55s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 14/15 [01:55<00:08,  8.60s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [02:03<00:00,  8.56s/it]\n",
      "\u001b[A\n",
      "100%|##########| 15/15 [02:03<00:00,  8.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [54:49<00:00, 657.98s/trial, best loss: -0.3145835527080493]\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"als\")\n",
    "        mlflow.log_params(params)\n",
    "        # Convert parameters to the appropriate format if needed\n",
    "        params['factors'] = int(params['factors'])\n",
    "        \n",
    "        # Initialize the model with the given parameters\n",
    "        model = implicit.als.AlternatingLeastSquares(**params, random_state = 42)\n",
    "        \n",
    "        # Fit the model and compute the desired metric (e.g., precision@k)\n",
    "        model.fit(csr_matrix)  # Replace with your data\n",
    "        score = get_model_score(model, csr_matrix, taste_profile)\n",
    "        mlflow.log_metric(\"recall\", score)\n",
    "    \n",
    "    return -score\n",
    "\n",
    "space = {\n",
    "    \"factors\": hp.quniform(\"factors\", 25, 100, 25),\n",
    "    \"regularization\": hp.uniform(\"regularization\", 0.01, 0.1), \n",
    "    \"alpha\": hp.loguniform(\"alpha\", 0, 1)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn= objective, \n",
    "    space = space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 5, \n",
    "    trials = trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "962fa1ff-09cd-476a-afcc-0e98d6793f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_als = {k: int(v) if k == \"factors\" else v for k, v in best.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a6f1c1fd-0d73-4361-be55-7a88b9e7b07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  3%|3         | 1/30 [00:01<00:55,  1.92s/it]\n",
      "\u001b[A\n",
      "  7%|6         | 2/30 [00:03<00:52,  1.88s/it]\n",
      "\u001b[A\n",
      " 10%|#         | 3/30 [00:05<00:49,  1.84s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 4/30 [00:07<00:47,  1.81s/it]\n",
      "\u001b[A\n",
      " 17%|#6        | 5/30 [00:09<00:45,  1.81s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 6/30 [00:10<00:39,  1.66s/it]\n",
      "\u001b[A\n",
      " 23%|##3       | 7/30 [00:11<00:35,  1.55s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 8/30 [00:13<00:33,  1.50s/it]\n",
      "\u001b[A\n",
      " 30%|###       | 9/30 [00:14<00:32,  1.54s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 10/30 [00:16<00:31,  1.57s/it]\n",
      "\u001b[A\n",
      " 37%|###6      | 11/30 [00:18<00:29,  1.56s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 12/30 [00:19<00:28,  1.60s/it]\n",
      "\u001b[A\n",
      " 43%|####3     | 13/30 [00:21<00:28,  1.65s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 14/30 [00:23<00:27,  1.69s/it]\n",
      "\u001b[A\n",
      " 50%|#####     | 15/30 [00:25<00:26,  1.76s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 16/30 [00:26<00:22,  1.62s/it]\n",
      "\u001b[A\n",
      " 57%|#####6    | 17/30 [00:27<00:19,  1.52s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 18/30 [00:29<00:18,  1.50s/it]\n",
      "\u001b[A\n",
      " 63%|######3   | 19/30 [00:31<00:17,  1.58s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 20/30 [00:32<00:16,  1.63s/it]\n",
      "\u001b[A\n",
      " 70%|#######   | 21/30 [00:34<00:15,  1.69s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 22/30 [00:36<00:13,  1.72s/it]\n",
      "\u001b[A\n",
      " 77%|#######6  | 23/30 [00:38<00:12,  1.74s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 24/30 [00:39<00:10,  1.71s/it]\n",
      "\u001b[A\n",
      " 83%|########3 | 25/30 [00:41<00:08,  1.72s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 26/30 [00:42<00:06,  1.59s/it]\n",
      "\u001b[A\n",
      " 90%|######### | 27/30 [00:44<00:04,  1.53s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 28/30 [00:45<00:03,  1.52s/it]\n",
      "\u001b[A\n",
      " 97%|#########6| 29/30 [00:47<00:01,  1.56s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [00:49<00:00,  1.60s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [00:49<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:44<26:58, 404.65s/trial, best loss: -0.13522417594153308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  3%|3         | 1/30 [00:02<01:16,  2.62s/it]\n",
      "\u001b[A\n",
      "  7%|6         | 2/30 [00:05<01:14,  2.67s/it]\n",
      "\u001b[A\n",
      " 10%|#         | 3/30 [00:07<01:10,  2.63s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 4/30 [00:10<01:09,  2.66s/it]\n",
      "\u001b[A\n",
      " 17%|#6        | 5/30 [00:13<01:09,  2.77s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 6/30 [00:16<01:07,  2.81s/it]\n",
      "\u001b[A\n",
      " 23%|##3       | 7/30 [00:19<01:03,  2.78s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 8/30 [00:21<01:00,  2.73s/it]\n",
      "\u001b[A\n",
      " 30%|###       | 9/30 [00:24<00:56,  2.67s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 10/30 [00:27<00:53,  2.67s/it]\n",
      "\u001b[A\n",
      " 37%|###6      | 11/30 [00:29<00:51,  2.71s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 12/30 [00:32<00:50,  2.82s/it]\n",
      "\u001b[A\n",
      " 43%|####3     | 13/30 [00:35<00:47,  2.80s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 14/30 [00:38<00:44,  2.76s/it]\n",
      "\u001b[A\n",
      " 50%|#####     | 15/30 [00:41<00:41,  2.75s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 16/30 [00:43<00:39,  2.81s/it]\n",
      "\u001b[A\n",
      " 57%|#####6    | 17/30 [00:47<00:37,  2.87s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 18/30 [00:49<00:34,  2.87s/it]\n",
      "\u001b[A\n",
      " 63%|######3   | 19/30 [00:53<00:32,  2.99s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 20/30 [00:56<00:29,  2.98s/it]\n",
      "\u001b[A\n",
      " 70%|#######   | 21/30 [00:59<00:27,  3.03s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 22/30 [01:02<00:25,  3.13s/it]\n",
      "\u001b[A\n",
      " 77%|#######6  | 23/30 [01:05<00:21,  3.08s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 24/30 [01:08<00:18,  3.05s/it]\n",
      "\u001b[A\n",
      " 83%|########3 | 25/30 [01:11<00:14,  2.99s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 26/30 [01:14<00:11,  2.96s/it]\n",
      "\u001b[A\n",
      " 90%|######### | 27/30 [01:17<00:08,  3.00s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 28/30 [01:20<00:05,  2.99s/it]\n",
      "\u001b[A\n",
      " 97%|#########6| 29/30 [01:23<00:02,  2.96s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [01:25<00:00,  2.88s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [01:25<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [14:26<21:54, 438.10s/trial, best loss: -0.1926494605112163] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  3%|3         | 1/30 [00:04<02:22,  4.93s/it]\n",
      "\u001b[A\n",
      "  7%|6         | 2/30 [00:10<02:23,  5.13s/it]\n",
      "\u001b[A\n",
      " 10%|#         | 3/30 [00:15<02:16,  5.07s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 4/30 [00:20<02:09,  4.97s/it]\n",
      "\u001b[A\n",
      " 17%|#6        | 5/30 [00:25<02:10,  5.20s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 6/30 [00:30<02:04,  5.18s/it]\n",
      "\u001b[A\n",
      " 23%|##3       | 7/30 [00:35<01:55,  5.00s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 8/30 [00:40<01:49,  4.97s/it]\n",
      "\u001b[A\n",
      " 30%|###       | 9/30 [00:45<01:46,  5.07s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 10/30 [00:51<01:44,  5.25s/it]\n",
      "\u001b[A\n",
      " 37%|###6      | 11/30 [00:55<01:35,  5.01s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 12/30 [01:01<01:33,  5.21s/it]\n",
      "\u001b[A\n",
      " 43%|####3     | 13/30 [01:06<01:27,  5.15s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 14/30 [01:11<01:20,  5.04s/it]\n",
      "\u001b[A\n",
      " 50%|#####     | 15/30 [01:15<01:13,  4.90s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 16/30 [01:20<01:09,  4.93s/it]\n",
      "\u001b[A\n",
      " 57%|#####6    | 17/30 [01:25<01:04,  4.97s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 18/30 [01:30<00:58,  4.91s/it]\n",
      "\u001b[A\n",
      " 63%|######3   | 19/30 [01:36<00:55,  5.09s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 20/30 [01:40<00:50,  5.01s/it]\n",
      "\u001b[A\n",
      " 70%|#######   | 21/30 [01:46<00:45,  5.08s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 22/30 [01:51<00:40,  5.06s/it]\n",
      "\u001b[A\n",
      " 77%|#######6  | 23/30 [01:55<00:34,  4.98s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 24/30 [02:00<00:29,  4.86s/it]\n",
      "\u001b[A\n",
      " 83%|########3 | 25/30 [02:06<00:25,  5.08s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 26/30 [02:11<00:20,  5.08s/it]\n",
      "\u001b[A\n",
      " 90%|######### | 27/30 [02:16<00:15,  5.26s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 28/30 [02:22<00:10,  5.30s/it]\n",
      "\u001b[A\n",
      " 97%|#########6| 29/30 [02:27<00:05,  5.16s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [02:31<00:00,  4.96s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [02:31<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [24:27<17:05, 512.78s/trial, best loss: -0.1926494605112163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  3%|3         | 1/30 [00:04<02:16,  4.72s/it]\n",
      "\u001b[A\n",
      "  7%|6         | 2/30 [00:10<02:26,  5.23s/it]\n",
      "\u001b[A\n",
      " 10%|#         | 3/30 [00:14<02:12,  4.91s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 4/30 [00:18<01:59,  4.58s/it]\n",
      "\u001b[A\n",
      " 17%|#6        | 5/30 [00:22<01:48,  4.34s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 6/30 [00:26<01:40,  4.17s/it]\n",
      "\u001b[A\n",
      " 23%|##3       | 7/30 [00:30<01:31,  3.98s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 8/30 [00:34<01:26,  3.93s/it]\n",
      "\u001b[A\n",
      " 30%|###       | 9/30 [00:38<01:24,  4.01s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 10/30 [00:41<01:17,  3.90s/it]\n",
      "\u001b[A\n",
      " 37%|###6      | 11/30 [00:45<01:12,  3.82s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 12/30 [00:49<01:09,  3.84s/it]\n",
      "\u001b[A\n",
      " 43%|####3     | 13/30 [00:53<01:05,  3.83s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 14/30 [00:56<01:00,  3.79s/it]\n",
      "\u001b[A\n",
      " 50%|#####     | 15/30 [01:00<00:56,  3.76s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 16/30 [01:04<00:51,  3.69s/it]\n",
      "\u001b[A\n",
      " 57%|#####6    | 17/30 [01:07<00:48,  3.70s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 18/30 [01:11<00:44,  3.73s/it]\n",
      "\u001b[A\n",
      " 63%|######3   | 19/30 [01:15<00:40,  3.69s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 20/30 [01:18<00:36,  3.66s/it]\n",
      "\u001b[A\n",
      " 70%|#######   | 21/30 [01:22<00:33,  3.68s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 22/30 [01:27<00:31,  3.98s/it]\n",
      "\u001b[A\n",
      " 77%|#######6  | 23/30 [01:31<00:28,  4.00s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 24/30 [01:35<00:23,  3.94s/it]\n",
      "\u001b[A\n",
      " 83%|########3 | 25/30 [01:38<00:19,  3.88s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 26/30 [01:42<00:15,  3.95s/it]\n",
      "\u001b[A\n",
      " 90%|######### | 27/30 [01:46<00:11,  3.97s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 28/30 [01:50<00:07,  3.93s/it]\n",
      "\u001b[A\n",
      " 97%|#########6| 29/30 [01:54<00:03,  3.92s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [01:58<00:00,  4.01s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [01:58<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [34:21<09:04, 544.60s/trial, best loss: -0.20023930594897846]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "  3%|3         | 1/30 [00:04<02:14,  4.62s/it]\n",
      "\u001b[A\n",
      "  7%|6         | 2/30 [00:10<02:35,  5.54s/it]\n",
      "\u001b[A\n",
      " 10%|#         | 3/30 [00:17<02:42,  6.03s/it]\n",
      "\u001b[A\n",
      " 13%|#3        | 4/30 [00:23<02:35,  5.97s/it]\n",
      "\u001b[A\n",
      " 17%|#6        | 5/30 [00:29<02:29,  6.00s/it]\n",
      "\u001b[A\n",
      " 20%|##        | 6/30 [00:34<02:15,  5.65s/it]\n",
      "\u001b[A\n",
      " 23%|##3       | 7/30 [00:39<02:02,  5.34s/it]\n",
      "\u001b[A\n",
      " 27%|##6       | 8/30 [00:43<01:51,  5.06s/it]\n",
      "\u001b[A\n",
      " 30%|###       | 9/30 [00:50<01:59,  5.69s/it]\n",
      "\u001b[A\n",
      " 33%|###3      | 10/30 [00:55<01:51,  5.58s/it]\n",
      "\u001b[A\n",
      " 37%|###6      | 11/30 [01:00<01:39,  5.24s/it]\n",
      "\u001b[A\n",
      " 40%|####      | 12/30 [01:05<01:33,  5.21s/it]\n",
      "\u001b[A\n",
      " 43%|####3     | 13/30 [01:12<01:38,  5.79s/it]\n",
      "\u001b[A\n",
      " 47%|####6     | 14/30 [01:20<01:42,  6.38s/it]\n",
      "\u001b[A\n",
      " 50%|#####     | 15/30 [01:27<01:39,  6.60s/it]\n",
      "\u001b[A\n",
      " 53%|#####3    | 16/30 [01:35<01:37,  6.94s/it]\n",
      "\u001b[A\n",
      " 57%|#####6    | 17/30 [01:41<01:29,  6.87s/it]\n",
      "\u001b[A\n",
      " 60%|######    | 18/30 [01:48<01:19,  6.63s/it]\n",
      "\u001b[A\n",
      " 63%|######3   | 19/30 [01:54<01:13,  6.67s/it]\n",
      "\u001b[A\n",
      " 67%|######6   | 20/30 [02:01<01:07,  6.73s/it]\n",
      "\u001b[A\n",
      " 70%|#######   | 21/30 [02:08<01:01,  6.87s/it]\n",
      "\u001b[A\n",
      " 73%|#######3  | 22/30 [02:13<00:50,  6.35s/it]\n",
      "\u001b[A\n",
      " 77%|#######6  | 23/30 [02:18<00:41,  5.87s/it]\n",
      "\u001b[A\n",
      " 80%|########  | 24/30 [02:25<00:37,  6.18s/it]\n",
      "\u001b[A\n",
      " 83%|########3 | 25/30 [02:30<00:29,  5.81s/it]\n",
      "\u001b[A\n",
      " 87%|########6 | 26/30 [02:36<00:22,  5.70s/it]\n",
      "\u001b[A\n",
      " 90%|######### | 27/30 [02:41<00:16,  5.61s/it]\n",
      "\u001b[A\n",
      " 93%|#########3| 28/30 [02:48<00:12,  6.07s/it]\n",
      "\u001b[A\n",
      " 97%|#########6| 29/30 [02:56<00:06,  6.66s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [03:03<00:00,  6.70s/it]\n",
      "\u001b[A\n",
      "100%|##########| 30/30 [03:03<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [48:19<00:00, 579.96s/trial, best loss: -0.21217974749576204]\n"
     ]
    }
   ],
   "source": [
    "def objective_lmf(params):\n",
    "    with mlflow.start_run(): \n",
    "        mlflow.set_tag(\"model\", \"lmf\")\n",
    "        mlflow.log_params(params)\n",
    "        # Convert parameters to the appropriate format if needed\n",
    "        params['factors'] = int(params['factors'])\n",
    "        \n",
    "        # Initialize the model with the given parameters\n",
    "        model = implicit.lmf.LogisticMatrixFactorization(**params, random_state = 42)\n",
    "        \n",
    "        # Fit the model and compute the desired metric (e.g., precision@k)\n",
    "        model.fit(csr_matrix)  # Replace with your data\n",
    "        score = get_model_score(model, csr_matrix, taste_profile)\n",
    "        mlflow.log_metric(\"recall\", score)\n",
    "    \n",
    "    return -score\n",
    "\n",
    "space_lmf = {\n",
    "    \"factors\": hp.quniform(\"factors\", 25, 100, 25),\n",
    "    \"regularization\": hp.uniform(\"regularization\", 0.1, 1), \n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", 0, 1)\n",
    "}\n",
    "\n",
    "trials_lmf = Trials()\n",
    "best_lmf = fmin(\n",
    "    fn= objective_lmf, \n",
    "    space = space_lmf, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 5, \n",
    "    trials = trials_lmf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "405488e2-3a7c-4fb8-aa2d-40cb7ff8dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lmf = {k: int(v) if k == \"factors\" else v for k, v in best_lmf.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "02b798a4-0e43-45d5-a583-2f7df50a6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taste_profile[taste_profile.numeric_song_id.isin(recommendations)][\"song\"].unique()\n",
    "#taste_profile[taste_profile.numeric_song_id.isin(recommendations_alt)][\"song\"].unique()\n",
    "#taste_profile[taste_profile.numeric_song_id.isin(rec)][\"song\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a7d762e3-b7e2-47c2-8807-ec23c8c94683",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = get_ground_truth(taste_profile, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3f02281d-9936-47fb-a6a7-5b8ddea2b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_als = taste_profile[taste_profile.numeric_song_id.isin(recommendations)][\"song\"].unique().tolist()\n",
    "recommendations_lmf = taste_profile[taste_profile.numeric_song_id.isin(rec)][\"song\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "84a63bbb-ce08-48fa-86b8-eb8ea51bd7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.4979221661440207,\n",
       " 'factors': 100,\n",
       " 'regularization': 0.06388396548115775}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "fbb05036-bf70-48df-b53d-3369ac73eab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/21 06:34:54 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2023/08/21 06:34:54 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4d7b4527-7923-41ef-bcad-90290b867108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:47<00:00, 15.16s/it]\n"
     ]
    }
   ],
   "source": [
    "best_als = implicit.als.AlternatingLeastSquares(factors = best_params_als[\"factors\"], alpha = best_params_als[\"alpha\"], regularization = best_params_als[\"regularization\"])\n",
    "best_als.fit(csr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85063e-fcbd-4846-9856-66bc755fb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = client.list_run_infos(experiment_id = \"1\")[0].run_id\n",
    "mlflow.register_model(\n",
    "    model_uri= f\"runs:/{run_id}/models\", \n",
    "    name = \"altenatingleastsquares\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4db8020d-0e11-4b27-826f-e460f9fb7f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [15:40<00:00, 31.36s/it]\n"
     ]
    }
   ],
   "source": [
    "best_lmf = implicit.lmf.LogisticMatrixFactorization(factors = best_params_lmf[\"factors\"], learning_rate = best_params_lmf[\"learning_rate\"], regularization = best_params_lmf[\"regularization\"])\n",
    "best_lmf.fit(csr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596ba6d-4a2a-4472-b52c-dc6947632e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = client.list_run_infos(experiment_id = \"2\")[0].run_id\n",
    "mlflow.register_model(\n",
    "    model_uri= f\"runs:/{run_id}/models\", \n",
    "    name = \"logisticmatrixfactorization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f3b6a13d-6d9e-414b-b038-88cef96414a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [best_als, best_lmf]\n",
    "scores_list = []\n",
    "for model in models: \n",
    "    result = get_model_score(model, csr_matrix, taste_profile)\n",
    "    scores_list.append(result)\n",
    "best_model = models[np.argmax(scores_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "ca15484e-f87d-49fd-b7e0-78e6f8f4111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rec_model.pkl\", \"wb\") as f: \n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a93fa-42d7-4400-9674-bf1828f0cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_artifact(local_path=\"./rec_model.pkl\", artifact_path = \"models_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2563e2c3-c51d-49d3-bccc-3217e8d6c2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\wowdao\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy\n",
    "import implicit \n",
    "import mlflow\n",
    "from prefect import flow, task\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "import pickle \n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa44d528-dda4-4cee-aa17-9631d240596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc4cba0-dbbd-4462-8afc-f4f04ae88559",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def get_ground_truth(profile, user_id): \n",
    "    user_data = profile[profile[\"numeric_user_id\"] == user_id]\n",
    "    relevant_play_count = profile[\"play_count\"].quantile(0.50)\n",
    "    ground_truth = user_data[user_data[\"play_count\"] >= relevant_play_count][\"numeric_song_id\"].tolist()\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e04ed0a-8faa-428c-be42-698f6e69ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def convert_to_binary(recommendations, ground_truth): \n",
    "    binary_recommendations = []\n",
    "    for rec in recommendations: \n",
    "        if rec in ground_truth:\n",
    "            binary_recommendations.append(1)\n",
    "        else: \n",
    "            binary_recommendations.append(0)\n",
    "    return binary_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9669bb51-939d-4b80-997a-be6b98b9380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def get_model_score(model, matrix, profile):\n",
    "    n = 20\n",
    "    recall_scores = []\n",
    "    for user_id in profile[\"numeric_user_id\"].unique(): \n",
    "        ground_truth = get_ground_truth(profile, user_id)\n",
    "        recommendation, _ = model.recommend(user_id, matrix[n], N = n)\n",
    "        binary_recommendation = convert_to_binary(recommendation, ground_truth)\n",
    "        binary_ground_truth = convert_to_binary(ground_truth, ground_truth)\n",
    "        min_value = min(len(binary_ground_truth), len(binary_recommendation))\n",
    "        score = recall_score(binary_ground_truth[:min_value], binary_recommendation[:min_value])\n",
    "        recall_scores.append(score)\n",
    "    average_score = sum(recall_scores) / len(recall_scores)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddba2bf-e199-4f79-a7e5-a6d584ac5331",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(name = \"get_data\", retries = 3, retry_delay_seconds = 2)\n",
    "def read_and_prepare_data(user_item_path, song_info_path): \n",
    "    user_item = pd.read_csv(user_item_path, delimiter = \"\\t\", names = [\"user_id\", \"song_id\", \"play_count\"], engine = \"pyarrow\", dtype_backend = \"pyarrow\")\n",
    "    song_info = pd.read_csv(song_info_path, engine = \"pyarrow\", dtype_backend=\"pyarrow\")\n",
    "    sample_user_item = user_item.iloc[:10**6]\n",
    "    taste_profile = sample_user_item.merge(song_info, on = \"song_id\", how = \"left\")\n",
    "    taste_profile[\"song\"] = taste_profile[\"artist_name\"] + \" - \" + taste_profile[\"title\"]\n",
    "    taste_profile = taste_profile.drop(columns = [\"title\", \"artist_name\", \"release\", \"year\"]).reindex(columns = [\"user_id\", \"song_id\", \"song\", \"play_count\"])\n",
    "    taste_profile[\"numeric_user_id\"], _ = pd.factorize(taste_profile[\"user_id\"])\n",
    "    taste_profile[\"numeric_song_id\"], _ = pd.factorize(taste_profile[\"song_id\"])\n",
    "    taste_profile = taste_profile.drop(index = taste_profile[taste_profile.play_count >= 15].index)\n",
    "    train_profile = pd.DataFrame(columns = [\"user_id\", \"song_id\", \"song\", \"play_count\", \"numeric_user_id\", \"numeric_song_id\"])\n",
    "    test_profile = pd.DataFrame(columns = [\"user_id\", \"song_id\", \"song\", \"play_count\", \"numeric_user_id\", \"numeric_song_id\"])\n",
    "    \n",
    "    for user in taste_profile[\"user_id\"].unique():\n",
    "        data = taste_profile[taste_profile[\"user_id\"] == user]\n",
    "        if len(data) >= 5:\n",
    "            user_train, user_test = train_test_split(data, test_size = 0.2, random_state = 42)\n",
    "            train_profile = pd.concat([train_profile, user_train])\n",
    "            test_profile = pd.concat([test_profile, user_test])\n",
    "        else:\n",
    "            continue\n",
    "    sample_profile_train = train_profile.drop(columns = [\"user_id\", \"song_id\"]).reindex(columns = [\"numeric_user_id\", \"numeric_song_id\", \"play_count\", \"song\"])\n",
    "    sample_profile_test = test_profile.drop(columns = [\"user_id\", \"song_id\"]).reindex(columns = [\"numeric_user_id\", \"numeric_song_id\", \"play_count\", \"song\"])\n",
    "    sample_profile_train = sample_profile_train.set_index([\"numeric_user_id\", \"numeric_song_id\"])\n",
    "    sample_profile_test = sample_profile_test.set_index([\"numeric_user_id\", \"numeric_song_id\"])\n",
    "\n",
    "    return sample_profile_train, sample_profile_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5ac90c-8af5-424f-bbc7-faba506571ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def process_data(sample_profile): \n",
    "    coo = scipy.sparse.coo_matrix(\n",
    "        (\n",
    "            sample_profile.play_count.astype(float), \n",
    "            (\n",
    "                sample_profile.index.get_level_values(0), \n",
    "                sample_profile.index.get_level_values(1),\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    csr_matrix = coo.tocsr()\n",
    "    return csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a42faa-1d2b-402a-b0d8-101b86fb86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def tune_model(rec_model, csr_matrix, taste_profile): \n",
    "    def objective(params):\n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag(\"model\", f\"{rec_model[1]}\")\n",
    "            mlflow.log_params(params)\n",
    "            # Convert parameters to the appropriate format if needed\n",
    "            params['factors'] = int(params['factors'])\n",
    "            \n",
    "            # Initialize the model with the given parameters\n",
    "            if rec_model[1] == \"als\":\n",
    "                model = rec_model[0].AlternatingLeastSquares(**params, random_state = 42)\n",
    "            elif rec_model[1] == \"lmf\": \n",
    "                model = rec_model[0].LogisticMatrixFactorization(**params, random_state = 42)\n",
    "            \n",
    "            # Fit the model and compute the desired metric (e.g., precision@k)\n",
    "            model.fit(csr_matrix)  # Replace with your data\n",
    "            score = get_model_score(model, csr_matrix, taste_profile)\n",
    "            mlflow.log_metric(\"recall\", score)\n",
    "        \n",
    "        return -score\n",
    "    if rec_model[1] == \"als\": \n",
    "        space = {\n",
    "            \"factors\": hp.quniform(\"factors\", 25, 100, 25),\n",
    "            \"regularization\": hp.uniform(\"regularization\", 0.01, 0.1), \n",
    "            \"alpha\": hp.loguniform(\"alpha\", 0, 1)\n",
    "        }\n",
    "        \n",
    "        trials = Trials()\n",
    "        best = fmin(\n",
    "            fn= objective, \n",
    "            space = space, \n",
    "            algo = tpe.suggest, \n",
    "            max_evals = 5, \n",
    "            trials = trials\n",
    "        )\n",
    "    elif rec_model[1] == \"lmf\": \n",
    "        space = {\n",
    "            \"factors\": hp.quniform(\"factors\", 25, 100, 25),\n",
    "            \"regularization\": hp.uniform(\"regularization\", 0.1, 1), \n",
    "            \"learning_rate\": hp.loguniform(\"learning_rate\", 0, 1)\n",
    "        }\n",
    "        \n",
    "        trials = Trials()\n",
    "        best = fmin(\n",
    "            fn= objective, \n",
    "            space = space, \n",
    "            algo = tpe.suggest, \n",
    "            max_evals = 5, \n",
    "            trials = trials\n",
    "        )\n",
    "        \n",
    "    best_params = {k: int(v) if k == \"factors\" else v for k, v in best.items()}\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69bafa39-98e6-406d-a29f-8a8183ffb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(log_prints = True) \n",
    "def train_best_model(profile_train, matrix_train, profile_test, matrix_test): \n",
    "    als_model = (implicit.als, \"als\")\n",
    "    lmf_model = (implicit.lmf, \"lmf\") \n",
    "    models = [als_model, lmf_model]\n",
    "    params_list = []\n",
    "    for model in models: \n",
    "        param = tune_model(model, matrix_train, profile_train)\n",
    "        params_list.append(param)\n",
    "    best_als = als_model[0].AlternatingLeastSquares(factors = params_list[0][\"factors\"], alpha = params_list[0][\"alpha\"], regularization = params_list[0][\"regularization\"])\n",
    "    best_als.fit(matrix_train)\n",
    "    best_lmf = lmf_model[0].LogisticMatrixFactorization(factors = params_list[1][\"factors\"], learning_rate = params_list[1][\"learning_rate\"], regularization = params_list[1][\"regularization\"])\n",
    "    best_lmf.fit(matrix_train)\n",
    "\n",
    "    best_models = [best_als, best_lmf]\n",
    "    scores_list_train = []\n",
    "    scores_list_test = []\n",
    "    for model in best_models: \n",
    "        result_train = get_model_score(model, matrix_train, profile_train)\n",
    "        scores_list_train.append(result_train)\n",
    "        result_test = get_model_score(model, matrix_test, profile_test)\n",
    "        scores_list_test.append(result_test)\n",
    "    best_model = best_models[np.argmax(scores_list_test)]\n",
    "\n",
    "    with open(\"rec_model.pkl\", \"wb\") as f: \n",
    "        pickle.dump(best_model, f)\n",
    "    mlflow.log_artifact(local_path=\"./rec_model.pkl\", artifact_path = \"models_pickle\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dcc3b7-1b99-47cd-8569-b9d9824ddc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">07:37:05.260 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'yellow-urchin'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'main-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "07:37:05.260 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'yellow-urchin'\u001b[0m for flow\u001b[1;35m 'main-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">07:37:06.194 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'yellow-urchin'</span> - Created task run 'get_data-0' for task 'get_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "07:37:06.194 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'yellow-urchin'\u001b[0m - Created task run 'get_data-0' for task 'get_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">07:37:06.201 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'yellow-urchin'</span> - Executing 'get_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "07:37:06.201 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'yellow-urchin'\u001b[0m - Executing 'get_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@flow\n",
    "def main_flow(user_item_path = \"./train_triplets.txt/train_triplets.txt\", song_info_path = \"./song_data.csv\"): \n",
    "    mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    mlflow.set_experiment(\"music-recommender-experiment\")\n",
    "    \n",
    "    profile_train, profile_test = read_and_prepare_data(user_item_path, song_info_path)\n",
    "    matrix_train, matrix_test = process_data(profile_train), process_data(profile_test)\n",
    "\n",
    "    train_best_model(profile_train, matrix_train, profile_test, matrix_test)\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc134ad-5f80-4d50-a947-a51954f643ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
